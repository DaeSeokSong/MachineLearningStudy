1. 층의 깊이에 비례해 정확도가 좋아진다.

2. 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 (혹은 그 이상의)
   수준의 표현력을 달성할 수 있다.

3. 매개변수 수는 층을 반복할 수록 적어지고 개수의 차이는 층이 깊어질 수록 커진다.
   작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은
   수용 영역(receptive field)을 소화할 수 있고 층을 거듭하면서 ReLU 등의 활성화 함수를
   합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선된다.
* 필터를 거칠 수록 윈도우의 사이즈가 작아지기 때문에 층을 거듭할 수록 개수 적어진다.
* 수용 영역 : 뉴런에 변화를 일으키는 국소적인 공간

4. 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.
   신경망을 깊게 하면 학습해야 할 문제를 계층적으로 분해할 수 있어서 각 층이
   학습해야 할 문제를 더 단순한 문제로 대채할 수 있는 것이다.
ㄴ Ex. 필터 과정 : 에지 → 구체적인 에지 → 좀 더 구체적인 에지 → 이미지
ㄴ 위와 같은 과정을 단층 신경망이면 필터가 바로 이미지로 적용되서 정확도가 떨어진다.

5. 정보를 계층적으로 전달할 수 있어서 더 고도의 패턴을 효과적으로 학습할 수 있다.

* 층의 심화는 층이 깊어도 제대로 학습할 수 있도록 해준느 기술과 환경이 뒷받침되야 한다.
Ex. 빅데이터와 검퓨터 연산 능력(하드웨어적 능력) 등